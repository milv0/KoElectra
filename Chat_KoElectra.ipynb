{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcd7de7-3560-43d4-8cdf-348f534e7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import openai\n",
    "import re\n",
    "import warning\n",
    "\n",
    "from torch.utils.data import dataloader\n",
    "\n",
    "# KoElectra \n",
    "from model.dataloader_electra import WellnessTextClassificationDataset\n",
    "from model.classifier_electra import KoELECTRAforSequenceClassfication\n",
    "from transformers import ElectraModel, ElectraConfig, ElectraTokenizer\n",
    "\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*resume_download.*\", category=FutureWarning)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d582d8-ba61-4ab7-9998-e67e2991eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 경로 지정\n",
    "root_path = \".\"\n",
    "\n",
    "data_path = f\"{root_path}/data/new_input_v2.txt\"\n",
    "answer_path = f\"{root_path}/data/new_answer.txt\"\n",
    "category_path = f\"{root_path}/data/new_category_v2.txt\"\n",
    "checkpoint_path = f\"{root_path}/checkpoint/new_electra_v5.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c63eaa-101d-42f2-96bf-a0529e7b4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wellness_answer():\n",
    "\n",
    "    c_f = open(category_path, 'r')\n",
    "    a_f = open(answer_path, 'r')\n",
    "\n",
    "    category_lines = c_f.readlines()\n",
    "    answer_lines = a_f.readlines()\n",
    "\n",
    "    category = {}\n",
    "    answer = {}\n",
    "    for line_num, line_data in enumerate(category_lines):\n",
    "        data = line_data.split('    ')\n",
    "        if len(data) != 2:\n",
    "            print(f\"Error in category file at line {line_num}: {line_data}\")\n",
    "        category[data[1][:-1]] = data[0]\n",
    "\n",
    "    for line_num, line_data in enumerate(answer_lines):\n",
    "        data = line_data.split('    ')\n",
    "        keys = answer.keys()\n",
    "        if len(data) != 2:\n",
    "            print(f\"Error in answer file at line {line_num}: {line_data}\")\n",
    "        if (data[0] in keys):\n",
    "            answer[data[0]] += [data[1][:-1]]\n",
    "        else:\n",
    "            answer[data[0]] = [data[1][:-1]]\n",
    "    return category, answer\n",
    "\n",
    "\n",
    "def load_model(checkpoint_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_config = ElectraConfig.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "    model = KoELECTRAforSequenceClassfication(model_config, num_labels=432, hidden_dropout_prob=0.1)    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "    return model, tokenizer, device\n",
    "\n",
    "def preprocess_input(tokenizer, sent, device, max_seq_len=512):\n",
    "    index_of_words = tokenizer.encode(sent)\n",
    "    token_type_ids = [0] * len(index_of_words)\n",
    "    attention_mask = [1] * len(index_of_words)\n",
    "    padding_length = max_seq_len - len(index_of_words)\n",
    "    index_of_words += [0] * padding_length\n",
    "    token_type_ids += [0] * padding_length\n",
    "    attention_mask += [0] * padding_length\n",
    "\n",
    "    data = {\n",
    "        'input_ids': torch.tensor([index_of_words]).to(device),\n",
    "        'token_type_ids': torch.tensor([token_type_ids]).to(device),\n",
    "        'attention_mask': torch.tensor([attention_mask]).to(device),\n",
    "        }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3305df1-4d50-4b99-bc4e-133206dbdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd28d5b-1e00-4ded-a175-341a6ac42c1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_answer(category, answer, output, input_sentence): # 수정\n",
    "    softmax_logit = torch.softmax(output[0], dim=-1).squeeze()\n",
    "    max_index = torch.argmax(softmax_logit).item()\n",
    "    max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n",
    "\n",
    "    ####### threshold 값 조절 #######\n",
    "    threshold = 0.5  \n",
    "    ####### threshold 값 조절 #######\n",
    "\n",
    "    selected_categories = []\n",
    "    for i, value in enumerate(softmax_logit):\n",
    "        if value > threshold:\n",
    "            if str(i) in category:\n",
    "                selected_categories.append(category[str(i)])\n",
    "                print(f\"Softmax 값 : ({max_index_value}) : {category[str(i)]}\")\n",
    "\n",
    "    # 선택된 카테고리가 없을 경우 예외처리\n",
    "    if not selected_categories:\n",
    "        return \"선택된 카테고리가 없습니다. 다시 입력해주세요\", None, max_index_value, []\n",
    "    \n",
    "    # 선택된 카테고리들에 해당하는 답변을 리스트에 저장\n",
    "    all_answers = []\n",
    "    for category_name in selected_categories:\n",
    "        if category_name in answer:\n",
    "            all_answers.extend(answer[category_name])\n",
    "\n",
    "    # 만약 답변이 없다면 예외처리\n",
    "    if not all_answers:\n",
    "        return \"선택된 카테고리에 대한 답변이 없습니다.\", None, max_index_value, []\n",
    "\n",
    "    # 답변들 중에서 랜덤으로 선택된 답변 출력\n",
    "    selected_answer = random.choice(all_answers)\n",
    "    # print(\"선택된 카테고리에 해당하는 모든 답변:\")\n",
    "    # print(all_answers)\n",
    "\n",
    "\n",
    "    return selected_answer, selected_categories, max_index_value, all_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24b299c-4eb5-4e3b-aa63-0af0759f9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_sentence(input_sentence, candidate_sentences, output):\n",
    "\n",
    "    model = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    def get_sentence_embedding(sentence):\n",
    "        inputs = tokenizer.encode_plus(sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        sentence_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "        return sentence_embedding\n",
    "\n",
    "    # 입력 문장 임베딩 구하기\n",
    "    input_embedding = get_sentence_embedding(input_sentence)\n",
    "\n",
    "    max_similarity = -1\n",
    "    selected_sentence = None  # 기본값으로 None 할당\n",
    "\n",
    "    similarities = []\n",
    "    top_similarities = []  # 함수 범위에서 초기화\n",
    "\n",
    "    for candidate in candidate_sentences:\n",
    "        candidate_embedding = get_sentence_embedding(candidate)\n",
    "        similarity = torch.cosine_similarity(input_embedding, candidate_embedding, dim=1)\n",
    "        similarities.append((candidate, similarity.item()))\n",
    "\n",
    "        # 유사도 상위 5개 문장 선택\n",
    "        top_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "    # top_similarities 리스트가 비어있는 경우 예외처리\n",
    "    if not top_similarities:\n",
    "        print(\"유사한 문장이 없습니다.\")\n",
    "        return None\n",
    "\n",
    "    # 상위 5개 중에서 랜덤으로 하나 선택\n",
    "    selected_sentence, _ = random.choice(top_similarities)\n",
    "\n",
    "    print(\"유사도 상위 3개 문장과 유사도 수치:\")\n",
    "    for sentence, similarity in top_similarities:\n",
    "        print(f\"유사도: {similarity:.4f} , 문장: {sentence}\" )\n",
    "\n",
    "    return selected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b79142-df71-4d86-9087-eee42a56ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "기룡이의 말투를 정해주세요\n",
    "\n",
    "1. \"저는 심리상담을 전문으로 하는 AI 기룡이 입니다.\"\n",
    "    - 매우 공식적이고 예의바른 말투 / 전문성과 신뢰감을 주는 인상\n",
    "2. \"나는 심리 상담 챗봇 AI 기룡이야!\"\n",
    "    - 친근하고 편안한 말투로 반말 체를 사용 / 좀 더 친구같고 가벼운 느낌\n",
    "3. \"저는 심리 상담을 해주는 AI 기룡이에요.\"\n",
    "    - 예의바르면서도 부드럽고 온화한 말투 /  상대방을 존중하지만 거리감은 크지 않음\n",
    "\"\"\"\n",
    "\n",
    "def gpt(input_sentence, selected_categories, chatbot_type):\n",
    "    openai.api_key = \"OPENAI_KEY\"\n",
    "    \n",
    "    # MODEL = \"gpt-3.5-turbo\"\n",
    "    MODEL = \"gpt-4-turbo\"\n",
    "\n",
    "    # 감정 분류 모델에서 예측한 카테고리\n",
    "    predicted_category = selected_categories\n",
    "\n",
    "    # 입력받은 사용자 문장\n",
    "    user_input = input_sentence\n",
    "\n",
    "    # 프롬프트 설정\n",
    "    prompts = {\n",
    "        \"formal\": f\"예측한 카테고리는 '{predicted_category}'입니다. 사용자 문장과 예측한 카테고리를 기반으로 매우 공식적인 말투(~다 로 끝나는)로 심리 상담 챗봇에 쓸 답변을 생성해주세요. 답변은 100자 이하로 만들어주세요.\",\n",
    "        \"casual\": f\"예측한 카테고리는 '{predicted_category}'입니다. 사용자 문장과 예측한 카테고리를 기반으로 도움과 격려가 되는 친근하고 편안한 말투로 반말 체를 사용하여 심리 상담 챗봇에 쓸 답변을 생성해주세요. 답변은 100자 이하로 만들어주세요.\",\n",
    "        \"polite\" : f\"The predicted category is '{predicted_category}. Based on your sentences and predicted categories, please create answers for your psychological counseling chatbot with a friendliness, polite tone that is helpful and encouraging. Please make your answers up to 200 characters\",\n",
    "        \"default\": f\"예측한 카테고리는 '{predicted_category}'입니다. 사용자 문장과 예측한 카테고리를 기반으로 도움과 격려가 되는\n",
    " 부드러운 문장으로 심리 상담 챗봇에 쓸 답변을 생성해주세요. 답변은 100자 이하로 만들어주세요.\"\n",
    "    }\n",
    "\n",
    "    # 임시로 랜덤 타입\n",
    "   # chatbot_type = random.randint(1, 3)\n",
    "    chatbot_type = 3\n",
    "    match chatbot_type:\n",
    "        case 1:\n",
    "            prompt = prompts.get(chatbot_type, prompts[\"formal\"])    # 공식적이고 예의바른 말투\n",
    "            print('<사무적인 말투>')\n",
    "        case 2:\n",
    "            prompt = prompts.get(chatbot_type, prompts[\"casual\"])    # 친근하고 편안한 말투로 반말 체\n",
    "            print('<친근한 반말투>')\n",
    "        case 3:\n",
    "            prompt = prompts.get(chatbot_type, prompts[\"polite\"])    # 예의바르면서도 부드럽고 온화한 말투\n",
    "            print('<부드러운 말투>')\n",
    "        case _:\n",
    "            prompt = prompts.get(chatbot_type, prompts[\"default\"])   # 기본\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.9,\n",
    "        max_tokens=200,\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # 응답 처리\n",
    "    original_response = response.choices[0].message.content\n",
    "    if not original_response.endswith('.'):\n",
    "        last_sentence = re.split(r'[.!?]', original_response)[-1].strip()\n",
    "        if last_sentence:\n",
    "            final_response = original_response + '.'\n",
    "        else:\n",
    "            final_response = original_response\n",
    "    else:\n",
    "        final_response = original_response\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130bfc38-b48a-4048-94e5-ebfb66be5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(checkpoint_path, category, answer):\n",
    "    model, tokenizer, device = load_model(checkpoint_path)\n",
    "\n",
    "    # cbt - ChatBot Type\n",
    "    cbt = input('기룡이의 말투를 선택해주세요 (1-딱딱함,2-반말,3-부드러움)')\n",
    "    chatbot_type = int(cbt)\n",
    "    \n",
    "    sent1 = input('\\nQuestion: ')\n",
    "    sent = str(sent1)\n",
    "            \n",
    "    data = preprocess_input(tokenizer, sent, device, 512)\n",
    "    output = model(**data)\n",
    "    answer, category, max_index_value, all_answers = get_answer(category, answer, output, sent)\n",
    "\n",
    "    # GPT API 답변 생성\n",
    "    chatbot_answer = gpt(sent,category, chatbot_type)\n",
    "    print(chatbot_answer)\n",
    "\n",
    "    # most_similar_sentence = find_most_similar_sentence(sent, all_answers, output)\n",
    "    # print(f'\\nsoftmax_value: {max_index_value}\\n문장 유사도 \\n가장 유사한 문장 : {most_similar_sentence} ')\n",
    "\n",
    "    print('-' * 70)\n",
    "\n",
    "# 카테고리 / 답변 로드        \n",
    "category, answer = load_wellness_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29b522-e642-42d7-b77f-82faaa08ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    chat(checkpoint_path, category, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccca61e-d4b6-4ecb-8a3b-bae0c4ee1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from konlpy.tag import Kkma\n",
    "\n",
    "# # Kkma 형태소 분석기 초기화\n",
    "# kkma = Kkma()\n",
    "# exclude_advs = ['못', '안']\n",
    "\n",
    "# # 예시 문장\n",
    "# sentence = \"나 너무 공부를 못 하는거 같아\"\n",
    "\n",
    "# # 형태소 분석\n",
    "# morphs = kkma.pos(sentence)\n",
    "\n",
    "# new_sentence = sentence\n",
    "# for i, (morph, pos) in enumerate(morphs):\n",
    "#     if pos == 'MAG' and morph not in exclude_advs:  # 'MAG'는 부사 태그, 제외 부사 목록 체크\n",
    "#         new_sentence = new_sentence.replace(morph + ' ', '')  # 부사 뒤의 공백도 제거\n",
    "\n",
    "# print(\"제거 문장:\", new_sentence.strip())  # 부사 제거 후 문장 출력\n",
    "# print()  # 줄바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db7b69-ac9b-464e-a403-f01e2b6ea17b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from konlpy.tag import Kkma\n",
    "\n",
    "# # Kkma 형태소 분석기 초기화\n",
    "# kkma = Kkma()\n",
    "\n",
    "# # 제외할 부사 목록\n",
    "# exclude_advs = ['못', '안']\n",
    "\n",
    "# # 텍스트 파일 열기\n",
    "# with open('testcase.txt', 'r', encoding='utf-8') as file:\n",
    "#     # 파일에서 한 줄씩 읽기\n",
    "#     for line in file:\n",
    "#         print(\"기존 문장:\", line.strip())  # 기존 문장 출력\n",
    "\n",
    "#         # 형태소 분석\n",
    "#         morphs = kkma.pos(line)\n",
    "\n",
    "#         new_line = line\n",
    "#         for i, (morph, pos) in enumerate(morphs):\n",
    "#             if pos == 'MAG' and morph not in exclude_advs:  # 'MAG'는 부사 태그, 제외 부사 목록 체크\n",
    "#                 new_line = new_line.replace(morph + ' ', '')  # 부사 뒤의 공백도 제거\n",
    "\n",
    "#         print(\"제거 문장:\", new_line.strip())  # 부사 제거 후 문장 출력\n",
    "#         print()  # 줄바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be4e8c-4908-40c8-9eef-1cf80676f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from konlpy.tag import Kkma\n",
    "\n",
    "# # Kkma 형태소 분석기 초기화\n",
    "# kkma = Kkma()\n",
    "\n",
    "# # 제외할 부사 목록\n",
    "# exclude_advs = ['못', '안']\n",
    "\n",
    "# # 텍스트 파일 열기\n",
    "# with open('testcase.txt', 'r', encoding='utf-8') as file:\n",
    "#     lines = file.readlines()  # 모든 줄을 읽어서 리스트로 저장\n",
    "\n",
    "# # 부사 제거된 문장들을 저장할 리스트\n",
    "# filtered_lines = []\n",
    "\n",
    "# for line in lines:\n",
    "#     # 형태소 분석\n",
    "#     morphs = kkma.pos(line)\n",
    "\n",
    "#     new_line = line\n",
    "#     for i, (morph, pos) in enumerate(morphs):\n",
    "#         if pos == 'MAG' and morph not in exclude_advs:  # 'MAG'는 부사 태그, 제외 부사 목록 체크\n",
    "#             new_line = new_line.replace(morph + ' ', '')  # 부사 뒤의 공백도 제거\n",
    "\n",
    "#     filtered_lines.append(new_line.strip())  # 부사 제거 후 문장을 리스트에 추가\n",
    "\n",
    "# # 새로운 파일에 결과 저장\n",
    "# with open('testcase_convert.txt', 'w', encoding='utf-8') as output_file:\n",
    "#     for line in filtered_lines:\n",
    "#         output_file.write(line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
