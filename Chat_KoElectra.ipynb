{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff78aacf-5d87-42f9-a0ac-4cb64342a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kobert-wellness-chatbot\n"
     ]
    }
   ],
   "source": [
    "# import문 보고 필요한 pip들 수동으로 설치하기 (requirements 하면 오류 많이 날수도)\n",
    "# torch 최신버전이면 다 될듯!\n",
    "!pwd\n",
    "# 폴더 만들어졌으면 구글 드라이브에서 다운로드 \n",
    "# model-v3 사용하면 됨 (임시로 epoch30으로 학습된 것)\n",
    "# 구글 드라이브 url : https://drive.google.com/drive/folders/1rmU70p2WEGA0sLhsw9WYowXrTj1y7M_g?usp=sharing\n",
    "\n",
    "# checkpoint 폴더 -> 모델 저장 (model-v3)\n",
    "# data 폴더 -> txt 파일들 저장(category, answer_v2 / input_v2는 학습할 때 사용해서 다운 안받아도 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4771cf-2c7d-4ae2-82ec-b8c3c61a92ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kobert-wellness-chatbot\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/kobert-wellness-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcd7de7-3560-43d4-8cdf-348f534e7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "from torch.utils.data import dataloader\n",
    "\n",
    "# KoElectra \n",
    "from model.dataloader_electra import WellnessTextClassificationDataset\n",
    "from model.classifier_electra import KoELECTRAforSequenceClassfication\n",
    "from transformers import ElectraModel, ElectraConfig, ElectraTokenizer\n",
    "\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# warning 출력 안되게\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d582d8-ba61-4ab7-9998-e67e2991eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 경로 지정\n",
    "root_path = \".\"\n",
    "data_path = f\"{root_path}/data/input_v4.txt\"\n",
    "category_path = f\"{root_path}/data/category.txt\"\n",
    "answer_path = f\"{root_path}/data/answer_v2.txt\"\n",
    "checkpoint_path = f\"{root_path}/checkpoint/model_electra_v2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c63eaa-101d-42f2-96bf-a0529e7b4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wellness_answer():\n",
    "\n",
    "    c_f = open(category_path, 'r')\n",
    "    a_f = open(answer_path, 'r')\n",
    "\n",
    "    category_lines = c_f.readlines()\n",
    "    answer_lines = a_f.readlines()\n",
    "\n",
    "    category = {}\n",
    "    answer = {}\n",
    "    for line_num, line_data in enumerate(category_lines):\n",
    "        data = line_data.split('    ')\n",
    "        if len(data) != 2:\n",
    "            print(f\"Error in category file at line {line_num}: {line_data}\")\n",
    "        category[data[1][:-1]] = data[0]\n",
    "\n",
    "    for line_num, line_data in enumerate(answer_lines):\n",
    "        data = line_data.split('    ')\n",
    "        keys = answer.keys()\n",
    "        if len(data) != 2:\n",
    "            print(f\"Error in answer file at line {line_num}: {line_data}\")\n",
    "        if (data[0] in keys):\n",
    "            answer[data[0]] += [data[1][:-1]]\n",
    "        else:\n",
    "            answer[data[0]] = [data[1][:-1]]\n",
    "    return category, answer\n",
    "\n",
    "\n",
    "def load_model(checkpoint_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_config = ElectraConfig.from_pretrained(\"monologg/koelectra-base-v3-generator\")\n",
    "    model = KoELECTRAforSequenceClassfication(model_config, num_labels=432, hidden_dropout_prob=0.1)    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-generator\")\n",
    "    return model, tokenizer, device\n",
    "\n",
    "def preprocess_input(tokenizer, sent, device, max_seq_len=512):\n",
    "    index_of_words = tokenizer.encode(sent)\n",
    "    token_type_ids = [0] * len(index_of_words)\n",
    "    attention_mask = [1] * len(index_of_words)\n",
    "    padding_length = max_seq_len - len(index_of_words)\n",
    "    index_of_words += [0] * padding_length\n",
    "    token_type_ids += [0] * padding_length\n",
    "    attention_mask += [0] * padding_length\n",
    "\n",
    "    data = {\n",
    "        'input_ids': torch.tensor([index_of_words]).to(device),\n",
    "        'token_type_ids': torch.tensor([token_type_ids]).to(device),\n",
    "        'attention_mask': torch.tensor([attention_mask]).to(device),\n",
    "        }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3305df1-4d50-4b99-bc4e-133206dbdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd28d5b-1e00-4ded-a175-341a6ac42c1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_answer(category, answer, output, input_sentence): # 수정\n",
    "    softmax_logit = torch.softmax(output[0], dim=-1).squeeze()\n",
    "    max_index = torch.argmax(softmax_logit).item()\n",
    "    max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n",
    "\n",
    "    ####### threshold 값 조절 #######\n",
    "    threshold = 0.3  \n",
    "    ####### threshold 값 조절 #######\n",
    "\n",
    "    selected_categories = []\n",
    "    for i, value in enumerate(softmax_logit):\n",
    "        if value > threshold:\n",
    "            if str(i) in category:\n",
    "                selected_categories.append(category[str(i)])\n",
    "                print(f\"Softmax 값이 threshold({threshold}) 이상인 카테고리: {category[str(i)]}\")\n",
    "\n",
    "    # 선택된 카테고리가 없을 경우 예외처리\n",
    "    if not selected_categories:\n",
    "        return \"선택된 카테고리가 없습니다. 다시 입력해주세요\", None, max_index_value, []\n",
    "    \n",
    "    # 선택된 카테고리들에 해당하는 답변을 리스트에 저장\n",
    "    all_answers = []\n",
    "    for category_name in selected_categories:\n",
    "        if category_name in answer:\n",
    "            all_answers.extend(answer[category_name])\n",
    "\n",
    "    # 만약 답변이 없다면 예외처리\n",
    "    if not all_answers:\n",
    "        return \"선택된 카테고리에 대한 답변이 없습니다.\", None, max_index_value, []\n",
    "\n",
    "    # 답변들 중에서 랜덤으로 선택된 답변 출력\n",
    "    selected_answer = random.choice(all_answers)\n",
    "    # print(\"선택된 카테고리에 해당하는 모든 답변:\")\n",
    "    # print(all_answers)\n",
    "\n",
    "\n",
    "    return selected_answer, selected_categories, max_index_value, all_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24b299c-4eb5-4e3b-aa63-0af0759f9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert_transformers import get_kobert_model\n",
    "\n",
    "def find_most_similar_sentence(input_sentence, candidate_sentences, output):\n",
    "    model = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-generator\")\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-generator\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    def get_sentence_embedding(sentence):\n",
    "        inputs = tokenizer.encode_plus(sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        sentence_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "        return sentence_embedding\n",
    "\n",
    "    # 입력 문장 임베딩 구하기\n",
    "    input_embedding = get_sentence_embedding(input_sentence)\n",
    "\n",
    "    # 후보 문장들과의 유사도 계산\n",
    "    max_similarity = -1\n",
    "    most_similar_sentence = None\n",
    "    for candidate in candidate_sentences:\n",
    "        candidate_embedding = get_sentence_embedding(candidate)\n",
    "        similarity = torch.cosine_similarity(input_embedding, candidate_embedding, dim=1)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_sentence = candidate\n",
    "\n",
    "    return most_similar_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130bfc38-b48a-4048-94e5-ebfb66be5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_main(checkpoint_path, category, answer):\n",
    "    model, tokenizer, device = load_model(checkpoint_path)\n",
    "\n",
    "    sent1 = input('\\nQuestion: ')\n",
    "    sent = str(sent1)\n",
    "    if '안녕?' in sent or '안녕!' in sent or '안녕' in sent:\n",
    "            print('Answer : 반가워요! 저는 기룡이에요!')\n",
    "            \n",
    "    data = preprocess_input(tokenizer, sent, device, 512)\n",
    "    output = model(**data)\n",
    "    answer, category, max_index_value, all_answers = get_answer(category, answer, output, sent)\n",
    "    # 유사한 문장 찾기\n",
    "    most_similar_sentence = find_most_similar_sentence(sent, all_answers, output)\n",
    "    print(f'index: {category} \\nsoftmax_value: {max_index_value} \\nAnswer: {answer} \\n가장 유사한 문장: {most_similar_sentence} ')\n",
    "    print('-' * 70)\n",
    "\n",
    "# 카테고리 / 답변 로드        \n",
    "category, answer = load_wellness_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82565883-c585-4f70-a2e8-43c193169033",
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1 :\n",
    "    chatbot_main(checkpoint_path, category, answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
